{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config_tf = tf.ConfigProto()\n",
    "config_tf.gpu_options.allow_growth = True\n",
    "config_tf.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\n",
    "sess = tf.Session(config=config_tf)\n",
    "\n",
    "import json\n",
    "# from keras.models import model_from_json\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import mpl_scatter_density\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.wrappers.scikit_learn import  KerasRegressor\n",
    "import keras.backend as K\n",
    "from importlib import reload\n",
    "from scipy.stats import median_abs_deviation\n",
    "import seaborn as sns\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"legend.fontsize\": \"x-large\",\n",
    "    \"axes.labelsize\": \"xx-large\",\n",
    "    \"axes.titlesize\": \"x-large\",\n",
    "    \"xtick.labelsize\": \"x-large\",\n",
    "    \"ytick.labelsize\": \"x-large\",\n",
    "    \"figure.facecolor\": \"w\",\n",
    "    \"xtick.top\": True,\n",
    "    \"ytick.right\": True,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"font.family\": \"serif\",\n",
    "    \"mathtext.fontset\": \"dejavuserif\",\n",
    "}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where your software library is saved\n",
    "# Clone the latest version of morphCaps branch from github\n",
    "path_photoz = '/home/bid13/code/photozCapsNet'\n",
    "\n",
    "sys.path.insert(1, path_photoz)\n",
    "path_photoz = Path(path_photoz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encapzulate.data_loader.data_loader import load_data\n",
    "from encapzulate.utils.fileio import load_model, load_config\n",
    "from encapzulate.utils import metrics\n",
    "from encapzulate.utils.utils import import_model\n",
    "from encapzulate.utils.metrics import Metrics, probs_to_redshifts, bins_to_redshifts\n",
    "\n",
    "# from encapzulate.utils.plots import better_step\n",
    "reload(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the exploration\n",
    "run_name = \"paper1_regression_80perc_0\" #\"morphCapsDeep_multi_15\" # \n",
    "checkpoint_eval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and set different paths\n",
    "# path_output = \"/data/bid13/photoZ/results\"\n",
    "path_output = \"/home/bid13/code/photozCapsNet/results\"\n",
    "path_output = Path(path_output)\n",
    "path_results = path_output / run_name.split(\"_\")[0] / run_name / \"results\" \n",
    "path_config =  path_results / \"config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config  = load_config(path_config)\n",
    "scale= config['image_scale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this wont be needed in future\n",
    "config[\"input_shape\"] = config[\"image_shape\"]\n",
    "CapsNet = import_model(model_name=config[\"model_name\"])\n",
    "train_model, eval_model,manipulate_model,decoder_model,redshift_model, = CapsNet(**config)\n",
    "manipulate_model.load_weights(\n",
    "    path_results / \"weights\" / f\"weights-{checkpoint_eval:02d}.h5\", by_name=True\n",
    ")\n",
    "# model = multi_gpu_model(eval_model,gpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./z_phot/all_paper1_regression_80perc_0_100.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_test = data[\"cat_test\"]\n",
    "y_caps_all = data[\"y_caps_all_test\"]\n",
    "y_prob = data[\"y_prob_test\"]\n",
    "morpho = np.argmax(y_prob, axis =-1)\n",
    "caps_test = y_caps_all[range(len(y_caps_all)),morpho,:]\n",
    "z_spec_test = data[\"z_spec_test\"]\n",
    "z_phot_test = data[\"z_phot_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_caps_all = data[\"y_caps_all_train\"]\n",
    "y_prob = data[\"y_prob_train\"]\n",
    "morpho = np.argmax(y_prob, axis =-1)\n",
    "caps_train = y_caps_all[range(len(y_caps_all)),morpho,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEEP SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a set of background examples to take an expectation over\n",
    "background = caps_train[np.random.choice(caps_train.shape[0], 1000, replace=False)]\n",
    "\n",
    "# explain predictions of the model on four images\n",
    "e = shap.DeepExplainer(redshift_model, background)\n",
    "# ...or pass tensors directly\n",
    "# e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)\n",
    "shap_values = e.shap_values(caps_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Dim \" + s for s in np.arange(1, config[\"dim_capsule\"] + 1).astype(str)]\n",
    "explainer = shap.Explanation(shap_values[0], data=caps_test, feature_names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.color_palette(\"flare\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(explainer, max_display=16, color=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = shap.GradientExplainer(\n",
    "    redshift_model,\n",
    "    caps_test,\n",
    "    batch_size=4096,\n",
    "    local_smoothing=0,  # std dev of smoothing noise\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = e.shap_values(caps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Dim \" + s for s in np.arange(1, config[\"dim_capsule\"] + 1).astype(str)]\n",
    "explainer = shap.Explanation(shap_values[0], data=caps_test, feature_names=names)\n",
    "cmap = sns.color_palette(\"flare\", as_cmap=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots(1,1,figsize=(10,20))\n",
    "shap.plots.beeswarm(explainer, max_display=16, color=cmap, color_bar_label=\"Dimension Value\",show=False)\n",
    "plt.savefig(\"./figs/shap_feature_importance.pdf\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(np.abs(explainer.values), axis=0)\n",
    "std = np.std(np.abs(explainer.values), axis=0)/np.sqrt(len(explainer.values))\n",
    "order = np.argsort(mean)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean[order])\n",
    "print(std[order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(mean[order],np.arange(16),xerr=std[order],fmt=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering = shap.utils.hclust(caps_test, z_spec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.bar(explainer, clustering=clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = [\"Dim \" + s for s in np.arange(1, config[\"dim_capsule\"] + 1).astype(str)]\n",
    "# explainer = shap.Explanation(shap_values[0], data=caps_test, feature_names=names)\n",
    "# cmap = sns.color_palette(\"flare\", as_cmap=True)\n",
    "# shap.plots.beeswarm(\n",
    "#     explainer, max_display=16, color=cmap, clustering=clustering, cluster_threshold=0.5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_trans(x,xmin=0,xmax=0.4):\n",
    "    return np.log((x-xmin)/(xmax-x))\n",
    "\n",
    "def logistic_trans_inv(x,xmin=0,xmax=0.4):\n",
    "    return (np.exp(x)*xmax + xmin)/(np.exp(x)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    model = redshift_model\n",
    "    model= multi_gpu_model(redshift_model)\n",
    "    model.compile(loss='mse', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model = KerasRegressor(build_fn=base_model, batch_size=2048, verbose=0)\n",
    "sklearn_model.model = base_model()\n",
    "zz = logistic_trans_inv(sklearn_model.predict(caps_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_scorer(estimator, X, z_spec):\n",
    "    z_phot = estimator.predict(X)\n",
    "    z_phot = logistic_trans_inv(z_phot, 0, 0.4)\n",
    "    error = (z_phot - z_spec) / (1 + z_spec)\n",
    "    sigma_nmad = 1.4826 * np.median(np.abs(error - np.median(error)))\n",
    "    return -1 * sigma_nmad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_level = np.abs(feature_importance_scorer(sklearn_model, caps_test, z_spec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(sklearn_model, caps_test, z_spec_test, n_repeats=100, n_jobs=1, scoring = feature_importance_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Permutation feature Importances\n",
    "$\\sigma_{NMAD}$ is used as the error metric for the feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import scale as mscale\n",
    "from matplotlib import transforms as mtransforms\n",
    "from matplotlib.ticker import AutoLocator, NullFormatter, NullLocator, ScalarFormatter\n",
    "\n",
    "\n",
    "class PowerLawScale(mscale.ScaleBase):\n",
    "    \"\"\" Custom class defining a Power law scaler for the axes\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"power_law\"\n",
    "\n",
    "    def __init__(self, axis, *, gamma, **kwargs):\n",
    "        super().__init__(axis)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def set_default_locators_and_formatters(self, axis):\n",
    "        \"\"\"\n",
    "        Default\n",
    "        \"\"\"\n",
    "        axis.set_major_locator(AutoLocator())\n",
    "        axis.set_major_formatter(ScalarFormatter())\n",
    "        axis.set_minor_locator(NullLocator())\n",
    "        axis.set_minor_formatter(NullFormatter())\n",
    "\n",
    "    def limit_range_for_scale(self, vmin, vmax, minpos):\n",
    "    \n",
    "        return vmin, vmax\n",
    "\n",
    "    def get_transform(self):\n",
    "        \"\"\"Set the actual transform for the axis coordinates.\n",
    " \n",
    "        \"\"\"\n",
    "        return self.PowerLawTransform(self.gamma)\n",
    "\n",
    "    class PowerLawTransform(mtransforms.Transform):\n",
    "        input_dims = output_dims = 1\n",
    "        def __init__(self, gamma):\n",
    "            mtransforms.Transform.__init__(self)\n",
    "            self.gamma = gamma\n",
    "\n",
    "        def transform_non_affine(self, a):\n",
    "            return np.sign(a)*np.power(np.abs(a), self.gamma)\n",
    "#             return np.power(a, self.gamma)\n",
    "\n",
    "        def inverted(self):\n",
    "            return PowerLawScale.InvertedPowerLawTransform( self.gamma)\n",
    "\n",
    "    class InvertedPowerLawTransform(mtransforms.Transform):\n",
    "        input_dims = output_dims = 1\n",
    "        def __init__(self, gamma):\n",
    "            mtransforms.Transform.__init__(self)\n",
    "            self.gamma = gamma\n",
    "\n",
    "        def transform_non_affine(self, a):\n",
    "            return np.sign(a)*np.power(np.abs(a), 1/self.gamma)\n",
    "\n",
    "        def inverted(self):\n",
    "            return PowerLawScale.PowerLawTransform(self.gamma)\n",
    "\n",
    "\n",
    "\n",
    "mscale.register_scale(PowerLawScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = result.importances / base_level\n",
    "median = np.median(importances, axis=-1)\n",
    "sorted_idx = median.argsort()\n",
    "spread = np.percentile(importances, [16, 84], axis=-1)\n",
    "spread[0, :] = median - spread[0, :]\n",
    "spread[1, :] = spread[1, :] - median\n",
    "names = np.arange(1, config[\"dim_capsule\"] + 1).astype(str)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "\n",
    "ax.errorbar(\n",
    "    median[sorted_idx],\n",
    "    names[sorted_idx],\n",
    "    xerr=spread[:, sorted_idx],\n",
    "    fmt=\"o\",\n",
    "    markersize=15,\n",
    "    elinewidth=2,\n",
    "    capsize=10,\n",
    "    capthick=2,\n",
    "    ls=\"\",\n",
    ")\n",
    "\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=25)\n",
    "ax.tick_params(axis=\"both\", which=\"minor\", labelsize=25)\n",
    "ax.set_ylabel(\"Capsule Dimension\", fontsize=40)\n",
    "ax.set_xlabel(\"Permutation Feature Importance\", fontsize=40)\n",
    "ax.grid(ls=\"--\")\n",
    "ax.set_xscale(\"power_law\", gamma=0.3)\n",
    "xticklabels = [0,0.01,0.1, 0.2,0.5,1,2,3,4]\n",
    "ax.set_xticks(xticklabels)\n",
    "ax.set_xticklabels([str(i) for i in xticklabels])\n",
    "fig.savefig(\"./figs/permutation_feature_importance.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = np.random.default_rng()\n",
    "perm = rand.permutation(len(caps_test))\n",
    "permuted = caps_test.copy()\n",
    "permuted[:,7]=permuted[perm,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = sklearn_model.predict(permuted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encapzulate.utils.metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met = Metrics(pred,z_spec_test,-4,1,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met.full_diagnostic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf15",
   "language": "python",
   "name": "tf15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
