{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=tf_config)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras import layers, models, optimizers, regularizers\n",
    "from keras.initializers import Constant\n",
    "from keras.callbacks import CSVLogger, LearningRateScheduler, ModelCheckpoint\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import (\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    "    Conv1D,\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Lambda,\n",
    "    Layer,\n",
    "    MaxPooling2D,\n",
    "    PReLU,\n",
    "    Reshape,\n",
    "    Softmax,\n",
    ")\n",
    "from keras.utils import to_categorical, multi_gpu_model\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change to your own path\n",
    "path_photoz = \"/home/bid13/code/encapZulate-1/src\"\n",
    "\n",
    "sys.path.insert(1, path_photoz)\n",
    "path_photoz = Path(path_photoz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import encapzulate\n",
    "from encapzulate.base.deepCapsLayers import (\n",
    "    CapsToScalars,\n",
    "    CapsuleLayer,\n",
    "    Conv2DCaps,\n",
    "    ConvCapsuleLayer3D,\n",
    "    ConvertToCaps,\n",
    "    FlattenCaps,\n",
    "    Mask_CID,\n",
    "    squash\n",
    ")\n",
    "from encapzulate.base.loss import (\n",
    "        margin_loss,\n",
    "        quantile_loss,\n",
    "        central_mse,\n",
    "        central_bias,\n",
    "    )\n",
    "from encapzulate.data_loader.data_loader import load_data\n",
    "from encapzulate.models.multi_gpu import MultiGPUModel\n",
    "from encapzulate.utils import metrics\n",
    "from encapzulate.utils.fileio import load_config, load_model\n",
    "from encapzulate.utils.metrics import Metrics, bins_to_redshifts, probs_to_redshifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "config:\n",
      "{   'bands': ('u', 'g', 'r', 'i', 'z'),\n",
      "    'batch_size': 200,\n",
      "    'checkpoint': None,\n",
      "    'compile_on': 'cpu',\n",
      "    'dataset': 'sdss_gz1_final_iter2',\n",
      "    'decay_rate': 0.95,\n",
      "    'dim_capsule': 16,\n",
      "    'epochs': 75,\n",
      "    'frac_dev': 0.1,\n",
      "    'frac_train': 0.02,\n",
      "    'image_scale': 10,\n",
      "    'image_shape': (64, 64, 5),\n",
      "    'img_augmentation': 1,\n",
      "    'lam_recon': 0.005,\n",
      "    'lam_redshift': 2,\n",
      "    'learning_rate': 0.001,\n",
      "    'logistic': True,\n",
      "    'model_name': 'morphCapsDeep_2',\n",
      "    'num_class': 2,\n",
      "    'num_gpus': 2,\n",
      "    'num_quantiles': False,\n",
      "    'path_data': '/data/bid13/photoZ/data/pasquet2019',\n",
      "    'path_results': None,\n",
      "    'random_state': 200,\n",
      "    'routings': 3,\n",
      "    'run_name': 'paper1_regression_2perc_4',\n",
      "    'timeline': False,\n",
      "    'use_vals': False,\n",
      "    'z_max': 0.4,\n",
      "    'z_min': 0.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = load_config(path_photoz / \"encapzulate\" / \"configs\" / \"morphCaps_4.yml\")\n",
    "config[\"run_name\"] = 'test_nb'\n",
    "config[\"input_shape\"] = config[\"image_shape\"]\n",
    "config[\"run_name\"] = \"test\"\n",
    "config[\"epochs\"] = 4\n",
    "config[\"frac_train\"] = 0.2\n",
    "config[\"learning_rate\"] = 0.001\n",
    "# config[\"decay_rate\"] = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = \"/home/bid13/code/photozCapsNet/results\"\n",
    "path_output = Path(path_output)\n",
    "path_results = (\n",
    "    path_output / config[\"run_name\"].split(\"_\")[0] / config[\"run_name\"] / \"results\"\n",
    ")\n",
    "path_logs = path_results / \"logs\"\n",
    "path_weights = path_results / \"weights\"\n",
    "path_logs.mkdir(parents=True, exist_ok=True)\n",
    "path_weights.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (x_train, y_train, vals_train, z_spec_train, cat_train),\n",
    "    (x_dev, y_dev, vals_dev, z_spec_dev, cat_dev),\n",
    "    (x_test, y_test, vals_test, z_spec_test, cat_test),\n",
    ") = load_data(load_cat=True, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapsNet(input_shape, num_class, routings, dim_capsule, **kwargs):\n",
    "    # assemble encoder\n",
    "    x = Input(shape=input_shape)\n",
    "    l = x\n",
    "\n",
    "    l = Conv2D(\n",
    "        128,\n",
    "        (3, 3),\n",
    "        strides=(1, 1),\n",
    "        activation=\"relu\",\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(\n",
    "        l\n",
    "    )  # common conv layer\n",
    "    l = BatchNormalization()(l)\n",
    "    l = ConvertToCaps()(l)\n",
    "\n",
    "    l = Conv2DCaps(\n",
    "        32, 4, kernel_size=(3, 3), strides=(2, 2), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l_skip = Conv2DCaps(\n",
    "        32, 4, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 4, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 4, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = layers.Add()([l, l_skip])\n",
    "\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(2, 2), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l_skip = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = layers.Add()([l, l_skip])\n",
    "\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(2, 2), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l_skip = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = layers.Add()([l, l_skip])\n",
    "    l1 = l\n",
    "\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(2, 2), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l_skip = ConvCapsuleLayer3D(\n",
    "        kernel_size=3,\n",
    "        num_capsule=32,\n",
    "        num_atoms=8,\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        routings=3,\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = Conv2DCaps(\n",
    "        32, 8, kernel_size=(3, 3), strides=(1, 1), r_num=1, b_alphas=[1, 1, 1]\n",
    "    )(l)\n",
    "    l = layers.Add()([l, l_skip])\n",
    "    l2 = l\n",
    "\n",
    "    la = FlattenCaps()(l2)\n",
    "    lb = FlattenCaps()(l1)\n",
    "    l = layers.Concatenate(axis=-2)([la, lb])\n",
    "\n",
    "    #     l = Dropout(0.4)(l)\n",
    "    digits_caps = CapsuleLayer(\n",
    "        num_capsule=num_class,\n",
    "        dim_capsule=dim_capsule,\n",
    "        routings=routings,\n",
    "        channels=0,\n",
    "        name=\"digit_caps\",\n",
    "    )(l)\n",
    "\n",
    "    l = CapsToScalars(name=\"capsnet\")(digits_caps)\n",
    "    # l = Softmax()(l)\n",
    "\n",
    "    m_capsnet = models.Model(inputs=x, outputs=l, name=\"capsnet_model\")\n",
    "\n",
    "    y = Input(shape=(num_class,))\n",
    "\n",
    "    masked_by_y = Mask_CID()([digits_caps, y])\n",
    "    masked = Mask_CID()(digits_caps)\n",
    "\n",
    "    # Redshift Network\n",
    "    # digits_caps_flat = Flatten()(digits_caps)\n",
    "    # val_input = Input(shape=(6,))\n",
    "    #     collect_layer = Concatenate()([digits_caps_flat, val_input, m_capsnet.output])\n",
    "    # collect_layer = Concatenate()([digits_caps_flat, m_capsnet.output])\n",
    "    #     redshift_input = Input(shape=(num_class * dim_capsule + 8,))\n",
    "    redshift_input = Input(shape=(dim_capsule,))\n",
    "    #     r = LayerNormalization()(redshift_input)\n",
    "    #     r = BatchNormalization(momentum=0.9)(redshift_input)\n",
    "    r = Dense(128, kernel_initializer=\"he_normal\")(redshift_input)\n",
    "    r = PReLU()(r)\n",
    "    r = Dense(64, kernel_initializer=\"he_normal\")(r)\n",
    "    r = PReLU()(r)\n",
    "    r = Dense(32, kernel_initializer=\"he_normal\")(r)\n",
    "    r = PReLU()(r)\n",
    "    r = Dense(16, kernel_initializer=\"he_normal\")(r)\n",
    "    r = PReLU()(r)\n",
    "    redshift_out = Dense(1)(r)\n",
    "    #     redshift_out = Dense(1)(redshift_input)\n",
    "    redshift = models.Model(redshift_input, redshift_out, name=\"redshift_model\")\n",
    "\n",
    "    # Decoder Network\n",
    "    decoder_input = Input(shape=(dim_capsule,))\n",
    "    d = Dense(\n",
    "        np.prod(input_shape),\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(decoder_input)\n",
    "    d = PReLU()(d)\n",
    "    d = Reshape(input_shape)(d)\n",
    "\n",
    "    d = Conv2DTranspose(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(d)\n",
    "    d = PReLU()(d)\n",
    "    d = Conv2DTranspose(\n",
    "        32,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(d)\n",
    "    d = PReLU()(d)\n",
    "    d = Conv2DTranspose(\n",
    "        16,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(d)\n",
    "    d = PReLU()(d)\n",
    "    d = Conv2DTranspose(8, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")(d)\n",
    "    d = PReLU()(d)\n",
    "    d = Conv2DTranspose(\n",
    "        input_shape[-1],\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        activation=\"tanh\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(d)\n",
    "    decoder_output = Reshape(target_shape=input_shape, name=\"out_recon\")(d)\n",
    "\n",
    "    decoder = models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
    "    train_model = models.Model(\n",
    "        [\n",
    "            x,\n",
    "            y,\n",
    "        ],\n",
    "        [m_capsnet.output, decoder(masked_by_y), redshift(masked_by_y)],\n",
    "    )\n",
    "\n",
    "    eval_model = models.Model(\n",
    "        [\n",
    "            x,\n",
    "        ],\n",
    "        [\n",
    "            masked,\n",
    "            digits_caps,\n",
    "            m_capsnet.output,\n",
    "            decoder(masked),\n",
    "            redshift(masked),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    manipulate_model = models.Model(\n",
    "        [\n",
    "            x,\n",
    "        ],\n",
    "        [masked, m_capsnet.output, decoder(masked), redshift(masked)],\n",
    "    )\n",
    "    train_model.summary()\n",
    "\n",
    "    return train_model, eval_model, manipulate_model, decoder, redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/tf15/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Tensor(\"conv_capsule_layer3d_1/stack:0\", shape=(5,), dtype=int32)\n",
      "WARNING:tensorflow:From /home/bid13/code/encapZulate-1/src/encapzulate/base/deepCapsLayers.py:446: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 128)  5888        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convert_to_caps_1 (ConvertToCap (None, 64, 64, 128,  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_1 (Conv2DCaps)      (None, 32, 32, 32, 4 147456      convert_to_caps_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_3 (Conv2DCaps)      (None, 32, 32, 32, 4 147456      conv2d_caps_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_4 (Conv2DCaps)      (None, 32, 32, 32, 4 147456      conv2d_caps_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_2 (Conv2DCaps)      (None, 32, 32, 32, 4 147456      conv2d_caps_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 32, 4 0           conv2d_caps_4[0][0]              \n",
      "                                                                 conv2d_caps_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_5 (Conv2DCaps)      (None, 16, 16, 32, 8 294912      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_7 (Conv2DCaps)      (None, 16, 16, 32, 8 589824      conv2d_caps_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_8 (Conv2DCaps)      (None, 16, 16, 32, 8 589824      conv2d_caps_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_6 (Conv2DCaps)      (None, 16, 16, 32, 8 589824      conv2d_caps_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 32, 8 0           conv2d_caps_8[0][0]              \n",
      "                                                                 conv2d_caps_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_9 (Conv2DCaps)      (None, 8, 8, 32, 8)  589824      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_11 (Conv2DCaps)     (None, 8, 8, 32, 8)  589824      conv2d_caps_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_12 (Conv2DCaps)     (None, 8, 8, 32, 8)  589824      conv2d_caps_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_10 (Conv2DCaps)     (None, 8, 8, 32, 8)  589824      conv2d_caps_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 32, 8)  0           conv2d_caps_12[0][0]             \n",
      "                                                                 conv2d_caps_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_13 (Conv2DCaps)     (None, 4, 4, 32, 8)  589824      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_14 (Conv2DCaps)     (None, 4, 4, 32, 8)  589824      conv2d_caps_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_caps_15 (Conv2DCaps)     (None, 4, 4, 32, 8)  589824      conv2d_caps_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_capsule_layer3d_1 (ConvCap (None, 4, 4, 32, 8)  18688       conv2d_caps_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 32, 8)  0           conv2d_caps_15[0][0]             \n",
      "                                                                 conv_capsule_layer3d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_caps_1 (FlattenCaps)    (None, 512, 8)       0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_caps_2 (FlattenCaps)    (None, 2048, 8)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2560, 8)      0           flatten_caps_1[0][0]             \n",
      "                                                                 flatten_caps_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "digit_caps (CapsuleLayer)       (None, 2, 16)        655392      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_cid_1 (Mask_CID)           (None, 16)           0           digit_caps[0][0]                 \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (CapsToScalars)         (None, 2)            0           digit_caps[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_model (Model)           (None, 64, 64, 5)    887717      mask_cid_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "redshift_model (Model)          (None, 1)            13297       mask_cid_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 8,364,470\n",
      "Trainable params: 8,364,214\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "Tensor(\"replica_0/model_1/conv_capsule_layer3d_1/stack:0\", shape=(5,), dtype=int32, device=/device:GPU:0)\n",
      "Tensor(\"replica_1/model_1/conv_capsule_layer3d_1/stack:0\", shape=(5,), dtype=int32, device=/device:GPU:1)\n"
     ]
    }
   ],
   "source": [
    "train_model, eval_model, manipulate_model, decoder, redshift_model = CapsNet(**config)\n",
    "parallel_train_model = MultiGPUModel(train_model, gpus=2)\n",
    "train_model = parallel_train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " compile_kwargs = {\n",
    "                \"optimizer\": optimizers.Adam(lr=config[\"learning_rate\"]),\n",
    "                \"loss\": [margin_loss, \"mse\", \"mse\"],\n",
    "                \"loss_weights\": [\n",
    "                    1.0,\n",
    "                    config[\"lam_recon\"] * np.prod(config[\"input_shape\"]),\n",
    "                    config[\"lam_redshift\"],\n",
    "                ],\n",
    "                \"metrics\": {\n",
    "                    \"capsnet\": \"accuracy\",\n",
    "                    \"redshift_model\": [central_mse(**config), central_bias(**config)],\n",
    "                },\n",
    "            }\n",
    "\n",
    "train_model.compile(**compile_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/tf15/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/tf15/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 103305 samples, validate on 51653 samples\n",
      "Epoch 1/4\n",
      "  1400/103305 [..............................] - ETA: 16:13 - loss: 4.6049 - capsnet_loss: 0.3021 - decoder_model_loss: 0.0167 - redshift_model_loss: 1.2951 - capsnet_accuracy: 0.4971 - redshift_model_central_mse_metric: 0.0076 - redshift_model_central_bias_metric: -0.0574"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ce14d7156fdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_spec_dev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf15/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf15/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf15/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf15/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "lr_decay = LearningRateScheduler(\n",
    "    schedule=lambda epoch: config[\"learning_rate\"] * (config[\"decay_rate\"] ** epoch)\n",
    ")\n",
    "log = CSVLogger(str(path_logs / \"log.csv\"))\n",
    "cp = ModelCheckpoint(\n",
    "    filepath=str(path_weights / \"weights-{epoch:02d}.h5\"),\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "# not doing img augmentation here\n",
    "train_model.fit(\n",
    "            [x_train, y_train],\n",
    "            [y_train, x_train, z_spec_train],\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            epochs=config[\"epochs\"],\n",
    "            initial_epoch=0,\n",
    "            validation_data=[[x_dev, y_dev], [y_dev, x_dev, z_spec_dev]],\n",
    "            callbacks=[log, cp, lr_decay],\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf15",
   "language": "python",
   "name": "tf15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
